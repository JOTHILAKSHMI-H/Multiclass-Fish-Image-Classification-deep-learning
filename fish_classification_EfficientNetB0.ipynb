{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBOkC3Pfvj6_"
      },
      "source": [
        "**Multiclass Fish Image Classification using Pre-trained models**\n",
        "\n",
        "**EfficientNetB0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-faG0Mm5qvoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacb4042-3734-4f5b-a22e-edb1bd0af5f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKIEw84Lutl-"
      },
      "outputs": [],
      "source": [
        "#import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torchvision.models import efficientnet_b0\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSwfBISlwFWr"
      },
      "outputs": [],
      "source": [
        "# set the device\n",
        "#This means you’ll run your model on GPU\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCe0ooQzwFSe"
      },
      "outputs": [],
      "source": [
        "#transformation for training data\n",
        "train_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomResizedCrop(224, scale = (0.8, 1.0)), #random zoom + crop\n",
        "        transforms.RandomHorizontalFlip(), #  flip the image (right ---> left)\n",
        "        transforms.RandomRotation(15), # random rotation clockwise or counter clockwise\n",
        "        transforms.ToTensor()   # #rescale to [0,1]\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDiX-GlxwFQm"
      },
      "outputs": [],
      "source": [
        " #for test and val\n",
        "# data preprocessing\n",
        "\n",
        "test_val_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224, 224)), #resize piexel same as training\n",
        "        transforms.ToTensor() #convert image to tensor\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtSUktG-wFBh"
      },
      "outputs": [],
      "source": [
        "# load the datasets\n",
        "train_datasets = datasets.ImageFolder('/content/drive/MyDrive/fish_image_classification_project_5/images.cv_jzk6llhf18tm3k0kyttxz/data/train', transform = train_transform)\n",
        "test_datasets = datasets.ImageFolder('/content/drive/MyDrive/fish_image_classification_project_5/images.cv_jzk6llhf18tm3k0kyttxz/data/test', transform = test_val_transform)\n",
        "val_datasets = datasets.ImageFolder('/content/drive/MyDrive/fish_image_classification_project_5/images.cv_jzk6llhf18tm3k0kyttxz/data/val', transform = test_val_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NE5FxWyw3SZ"
      },
      "outputs": [],
      "source": [
        "# create the dataloader\n",
        "train_data_loader = DataLoader(train_datasets, batch_size = 5, shuffle = True)\n",
        "test_data_loader = DataLoader(test_datasets, batch_size = 5, shuffle = True)\n",
        "val_data_loader = DataLoader(val_datasets, batch_size = 5, shuffle = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55BVRATyw3PQ",
        "outputId": "51d2b60e-7df8-4cba-d252-6ae84c5da111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 122MB/s]\n"
          ]
        }
      ],
      "source": [
        "# load the pre-trained  model EfficientNetB0\n",
        "model = models.efficientnet_b0(pretrained = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLvWq2mNw3NY"
      },
      "outputs": [],
      "source": [
        "model.classifier[1] = nn.Linear(in_features=1280, out_features=11)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7HDGdwGw3Kz"
      },
      "outputs": [],
      "source": [
        "#loss function and optimizer\n",
        "\n",
        "cl = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(),lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8m1tLdjw3I_",
        "outputId": "7e6704f8-8ba2-41e0-d091-b8bf9dccc3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], loss 902.8445\n",
            "Epoch [2/25], loss 444.5125\n",
            "Epoch [3/25], loss 361.9542\n",
            "Epoch [4/25], loss 345.1612\n",
            "Epoch [5/25], loss 329.6713\n",
            "Epoch [6/25], loss 305.8383\n",
            "Epoch [7/25], loss 279.1798\n",
            "Epoch [8/25], loss 286.0884\n",
            "Epoch [9/25], loss 271.3515\n",
            "Epoch [10/25], loss 279.0989\n",
            "Epoch [11/25], loss 270.8975\n",
            "Epoch [12/25], loss 264.9159\n",
            "Epoch [13/25], loss 279.1433\n",
            "Epoch [14/25], loss 267.3674\n",
            "Epoch [15/25], loss 284.7060\n",
            "Epoch [16/25], loss 280.6456\n",
            "Epoch [17/25], loss 251.2245\n",
            "Epoch [18/25], loss 250.8101\n",
            "Epoch [19/25], loss 240.2469\n",
            "Epoch [20/25], loss 257.0794\n",
            "Epoch [21/25], loss 258.5691\n",
            "Epoch [22/25], loss 241.7442\n",
            "Epoch [23/25], loss 278.9647\n",
            "Epoch [24/25], loss 271.6884\n",
            "Epoch [25/25], loss 271.1959\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "\n",
        "epochs = 25\n",
        "\n",
        "for i in range(epochs):\n",
        "  model.train()\n",
        "  total_loss = 0.0 # total running loss\n",
        "  total = 0 #  #  Total number of images evaluated\n",
        "  correct = 0 #  calculate how many predictions correct\n",
        "  for img, tar in train_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(img)\n",
        "    loss = cl(outputs, tar)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    correct += (preds == tar).sum().item()\n",
        "    total += tar.size(0)\n",
        "\n",
        "  print(f\"Epoch [{i + 1}/{epochs}], loss {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ6qJFiRw3HI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acb86d0-3f53-4cd2-dc4a-487f79b6a66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_accuracy: 97.53%\n",
            "val_precision: 94.08%\n",
            "val_recall: 95.40%\n",
            "val f1_score: 94.56%\n",
            "confusion matrix\n",
            "[[180   6   0   0   0   0   0   1   0   0   0]\n",
            " [  3   7   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0 105   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0  94   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  97   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  90   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 113   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0  96   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 100   0   0]\n",
            " [  0   0   2   1   0   5   0   1   7  85   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  98]]\n"
          ]
        }
      ],
      "source": [
        "#Evaluation on validation data\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_tars = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for img, tar in val_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "    outputs = model(img)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_tars.extend(tar.cpu().numpy())\n",
        "\n",
        "\n",
        "  #accuracy\n",
        "  accuracy = accuracy_score(all_tars, all_preds)\n",
        "  print(f\"val_accuracy: {accuracy*100 :.2f}%\")\n",
        "\n",
        "  #precision\n",
        "  precision = precision_score(all_tars , all_preds, average = 'macro')\n",
        "  print(f\"val_precision: {precision*100 :.2f}%\")\n",
        "\n",
        "  # recall\n",
        "  recall = recall_score(all_tars , all_preds, average = 'macro')\n",
        "  print(f\"val_recall: {recall*100 :.2f}%\")\n",
        "\n",
        "  #f1 score\n",
        "  f1score = f1_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"val f1_score: {f1score *100:.2f}%\")\n",
        "\n",
        "  # Calculate confusion matrix\n",
        "  cm = confusion_matrix(all_tars, all_preds)\n",
        "  print('confusion matrix')\n",
        "  print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hulf9FAJw3Dt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2143e8e4-88ed-47f6-ea8d-1896a492c7d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.77%\n",
            "Test precision: 92.57%\n",
            "Test recall: 96.09%\n",
            "Test f1_score: 93.55%\n",
            "confusion matrix\n",
            "[[500  19   0   0   0   0   0   1   0   0   0]\n",
            " [  3  10   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0 298   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0 298   0   0   3   3   0   0   0]\n",
            " [  0   0   1   1 284   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 291   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 273   0   0   0   0]\n",
            " [  2   0   1   3   0   0   0 321   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 289   0   0]\n",
            " [  0   0   5   0   2  19   0   2   4 261   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0 291]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluation on test data\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_tars = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for img, tar in test_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "    outputs = model(img)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_tars.extend(tar.cpu().numpy())\n",
        "\n",
        "\n",
        "# accuracy\n",
        "accuracy = accuracy_score(all_tars, all_preds)\n",
        "print(f\"Test Accuracy: {accuracy *100:.2f}%\")\n",
        "\n",
        "# precision\n",
        "precision = precision_score(all_tars, all_preds, average = 'macro')\n",
        "print(f\"Test precision: {precision *100:.2f}%\")\n",
        "\n",
        "#recall\n",
        "recall = recall_score(all_tars, all_preds, average = 'macro')\n",
        "print(f\"Test recall: {recall *100:.2f}%\")\n",
        "\n",
        "\n",
        "#f1 score\n",
        "f1score = f1_score(all_tars, all_preds, average = 'macro')\n",
        "print(f\"Test f1_score: {f1score *100:.2f}%\")\n",
        "\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(all_tars, all_preds)\n",
        "print('confusion matrix')\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKxLyr8Bw3Aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247fffa1-6a6a-4508-d54a-292d8f11a656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 98.55%\n",
            "Train precision: 93.98%\n",
            "Train recall:98.57%\n",
            "Train f1_score: 95.28%\n",
            "confusion matrix\n",
            "[[1054   40    1    0    0    0    0    1    0    0    0]\n",
            " [   1   29    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0  569    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0  564    0    0    0    1    0    0    1]\n",
            " [   1    0    5    0  567    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0  578    0    1    0    0    0]\n",
            " [   0    0    0    1    0    0  570    0    0    0    0]\n",
            " [   1    0    2    2    0    0    0  532    0    0    1]\n",
            " [   0    0    0    0    0    0    0    0  576    0    0]\n",
            " [   1    0    4    0    1   17    0    0    7  517    0]\n",
            " [   0    0    0    0    0    0    0    1    0    0  579]]\n"
          ]
        }
      ],
      "source": [
        "# evaluate the train data\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_tars = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  for img, tar in train_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "    outputs = model(img)\n",
        "    _,preds = torch.max(outputs, 1)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_tars.extend(tar.cpu().numpy())\n",
        "\n",
        "\n",
        "  # accuracy\n",
        "accuracy = accuracy_score(all_tars, all_preds)\n",
        "print(f\"Train Accuracy: {accuracy* 100:.2f}%\")\n",
        "\n",
        "  #precision\n",
        "precision = precision_score(all_tars, all_preds, average = 'macro')\n",
        "print(f\"Train precision: {precision*100:.2f}%\")\n",
        "\n",
        "  #recall\n",
        "recall = recall_score(all_tars, all_preds, average = 'macro')\n",
        "print(f\"Train recall:{recall*100:.2f}%\")\n",
        "\n",
        "#f1 score\n",
        "f1score = f1_score(all_tars, all_preds, average = 'macro')\n",
        "print(f\"Train f1_score: {f1score *100:.2f}%\")\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(all_tars, all_preds)\n",
        "print('confusion matrix')\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAYHasbpw256"
      },
      "outputs": [],
      "source": [
        "# save the model\n",
        "\n",
        "torch.save(model.state_dict(), 'efficientnetb0_fish_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKBCaKjWw22R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "435e3e8b-5802-4bd2-88a4-cd0090157651"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9decc991-36ab-46c9-9fc6-60630f2d3116\", \"efficientnetb0_fish_model.pth\", 16391354)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('efficientnetb0_fish_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmI5G7LFw200"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_3AIyyVw2UY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}