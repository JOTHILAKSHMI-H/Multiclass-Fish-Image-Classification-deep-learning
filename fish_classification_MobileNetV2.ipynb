{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Multiclass Fish Image Classification using Pre-trained models**\n",
        "\n",
        "**MobileNetV2**"
      ],
      "metadata": {
        "id": "FKBiVK8WLr9k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRgl1-V5Kf3B"
      },
      "outputs": [],
      "source": [
        "#import the required libraries\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rb0ffbusVki",
        "outputId": "0352c163-ccdd-4f1b-d4f9-b7cfd5a31e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set the device\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "U4i5Y-cOOIJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transformation for training data\n",
        "train_transform = transforms.Compose(\n",
        "    [\n",
        "\n",
        "        transforms.RandomResizedCrop(224, scale = (0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "8Xgt-BVfPj-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_val_transform = transforms.Compose(\n",
        "    [transforms.Resize((224,224)),\n",
        "     transforms.ToTensor()]\n",
        ")"
      ],
      "metadata": {
        "id": "OmWLh2PgQ6dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the datasets\n",
        "train_datasets = datasets.ImageFolder('/content/drive/MyDrive/images.cv_jzk6llhf18tm3k0kyttxz/data/train', transform = train_transform)\n",
        "test_datasets = datasets.ImageFolder('/content/drive/MyDrive/images.cv_jzk6llhf18tm3k0kyttxz/data/test', transform = test_val_transform)\n",
        "val_datasets = datasets.ImageFolder('/content/drive/MyDrive/images.cv_jzk6llhf18tm3k0kyttxz/data/val', transform = test_val_transform)"
      ],
      "metadata": {
        "id": "92MV1SMbSdRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloder\n",
        "\n",
        "train_data_loader = DataLoader(train_datasets, batch_size = 5, shuffle = True)\n",
        "test_data_loader = DataLoader(test_datasets, batch_size= 5, shuffle = True)\n",
        "val_data_loader = DataLoader(val_datasets, batch_size = 5, shuffle= True)\n"
      ],
      "metadata": {
        "id": "hj1wD1PgUMg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pre trained model MobileNet V2\n",
        "model = models.mobilenet_v2(pretrained = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9WGYBrbVSFu",
        "outputId": "89b93aa5-8793-4186-fd96-82b07f749400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 173MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier[1] = nn.Linear(model.last_channel, 11)"
      ],
      "metadata": {
        "id": "G4h4xnp7VRNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "uJ_ak_fRWJ9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss function and optimizer\n",
        "\n",
        "cl = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(),lr = 0.001)"
      ],
      "metadata": {
        "id": "VZYapFIVWShB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "epochs = 25\n",
        "for i in range(epochs):\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  for img,tar in train_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(img)\n",
        "    loss = cl(outputs, tar)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    _, pred = torch.max(outputs, 1)\n",
        "    correct += (pred == tar).sum().item()\n",
        "    total += tar.size(0)\n",
        "\n",
        "\n",
        "  print(f\"Epochs [{i + 1}/{epochs}], loss {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F96irwIXWdhv",
        "outputId": "cb95a438-24aa-4bf1-ded3-418d4b6455e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs [1/25], loss 370.2602\n",
            "Epochs [2/25], loss 410.4366\n",
            "Epochs [3/25], loss 371.0588\n",
            "Epochs [4/25], loss 374.4433\n",
            "Epochs [5/25], loss 377.6933\n",
            "Epochs [6/25], loss 378.3074\n",
            "Epochs [7/25], loss 378.7689\n",
            "Epochs [8/25], loss 378.0514\n",
            "Epochs [9/25], loss 389.6587\n",
            "Epochs [10/25], loss 385.8933\n",
            "Epochs [11/25], loss 368.1598\n",
            "Epochs [12/25], loss 426.0201\n",
            "Epochs [13/25], loss 368.6740\n",
            "Epochs [14/25], loss 350.4293\n",
            "Epochs [15/25], loss 368.9431\n",
            "Epochs [16/25], loss 402.4252\n",
            "Epochs [17/25], loss 413.1719\n",
            "Epochs [18/25], loss 345.7085\n",
            "Epochs [19/25], loss 369.6681\n",
            "Epochs [20/25], loss 378.1057\n",
            "Epochs [21/25], loss 393.7274\n",
            "Epochs [22/25], loss 350.4544\n",
            "Epochs [23/25], loss 394.5706\n",
            "Epochs [24/25], loss 380.4732\n",
            "Epochs [25/25], loss 429.0091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate validation data\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_tars = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for img, tar in val_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "    outputs = model(img)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_tars.extend(tar.cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "  #accuracy\n",
        "  accuracy = accuracy_score(all_tars, all_preds)\n",
        "  print(f\"val_accuracy: {accuracy* 100 :.2f}%\")\n",
        "\n",
        "  #precision\n",
        "  precision = precision_score(all_tars , all_preds, average = 'macro')\n",
        "  print(f\"val_precision: {precision * 100 :.2f}%\")\n",
        "\n",
        "  # recall\n",
        "  recall = recall_score(all_tars , all_preds, average = 'macro')\n",
        "  print(f\"val_recall: {recall *100 :.2f}%\")\n",
        "\n",
        "  #f1 score\n",
        "  f1score = f1_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"val_f1_score: {f1score *100:.2f}%\")\n",
        "\n",
        "  # Calculate confusion matrix\n",
        "  cm = confusion_matrix(all_tars, all_preds)\n",
        "  print('confusion matrix')\n",
        "  print(cm)"
      ],
      "metadata": {
        "id": "YWSpRrrCZq5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4864bab-ffaf-4fa0-8913-9f29ba1be9dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_accuracy: 98.90%\n",
            "val_precision: 97.51%\n",
            "val_recall: 98.15%\n",
            "val_f1_score: 97.80%\n",
            "confusion matrix\n",
            "[[185   2   0   0   0   0   0   0   0   0   0]\n",
            " [  1   9   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0 105   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0  90   1   0   3   0   0   0   0]\n",
            " [  0   0   0   0  97   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  90   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 113   0   0   0   0]\n",
            " [  0   0   1   1   0   0   0  95   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 100   0   0]\n",
            " [  0   0   1   0   1   1   0   0   0  98   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  98]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on test data\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_tars = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for img, tar in test_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "    outputs = model(img)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_tars.extend(tar.cpu().numpy())\n",
        "\n",
        "\n",
        "# accuracy\n",
        "  accuracy = accuracy_score(all_tars, all_preds)\n",
        "  print(f\"Test Accuracy: {accuracy *100:.2f}%\")\n",
        "\n",
        "# precision\n",
        "  precision = precision_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"Test precision: {precision *100:.2f}%\")\n",
        "\n",
        "#recall\n",
        "  recall = recall_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"Test recall: {recall *100:.2f}%\")\n",
        "\n",
        "#f1 score\n",
        "  f1score = f1_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"Test f1_score: {f1score *100:.2f}%\")\n",
        "\n",
        "# Calculate confusion matrix\n",
        "  cm = confusion_matrix(all_tars, all_preds)\n",
        "  print('confusion matrix')\n",
        "  print(cm)"
      ],
      "metadata": {
        "id": "hqMWhsYUZq1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9fc1dc-b285-4aae-d969-143a3bb7df0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.78%\n",
            "Test precision: 96.53%\n",
            "Test recall: 97.57%\n",
            "Test f1_score: 97.00%\n",
            "confusion matrix\n",
            "[[515   4   0   0   1   0   0   0   0   0   0]\n",
            " [  2  11   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0 298   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 295   0   0  10   0   0   0   0]\n",
            " [  0   0   0   0 286   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 287   0   0   0   4   0]\n",
            " [  0   0   0   0   0   0 273   0   0   0   0]\n",
            " [  0   0   6   4   0   0   0 316   0   1   0]\n",
            " [  0   0   0   0   0   0   0   0 289   0   0]\n",
            " [  0   0   0   0   1   1   0   0   0 291   0]\n",
            " [  0   0   0   1   0   0   0   4   0   0 287]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the train data\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_tars = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  for img, tar in train_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "    outputs = model(img)\n",
        "    _,preds = torch.max(outputs, 1)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_tars.extend(tar.cpu().numpy())\n",
        "\n",
        "\n",
        "# accuracy\n",
        "  accuracy = accuracy_score(all_tars, all_preds)\n",
        "  print(f\"Train Accuracy: {accuracy* 100:.2f}%\")\n",
        "\n",
        "#precision\n",
        "  precision = precision_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"Train precision: {precision*100:.2f}%\")\n",
        "\n",
        "#recall\n",
        "  recall = recall_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"Train recall:{recall*100:.2f}%\")\n",
        "\n",
        "\n",
        "#f1 score\n",
        "  f1score = f1_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"Train f1_score: {f1score *100:.2f}%\")\n",
        "\n",
        "# Calculate confusion matrix\n",
        "  cm = confusion_matrix(all_tars, all_preds)\n",
        "  print('confusion matrix')\n",
        "  print(cm)"
      ],
      "metadata": {
        "id": "Gylh04pdZqzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f44b45-b828-4c93-dce1-8a26251e7f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 99.21%\n",
            "Train precision: 96.95%\n",
            "Train recall:99.33%\n",
            "val f1_score: 97.95%\n",
            "confusion matrix\n",
            "[[1081   11    0    2    0    1    1    0    0    0    0]\n",
            " [   0   30    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0  568    0    1    0    0    0    0    0    0]\n",
            " [   0    0    0  559    3    0    3    1    0    0    0]\n",
            " [   0    0    0    0  573    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0  578    0    0    0    1    0]\n",
            " [   0    0    0    1    0    0  570    0    0    0    0]\n",
            " [   0    0    5    1    0    0    0  532    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  575    1    0]\n",
            " [   0    0    1    0    3    1    0    0    0  541    1]\n",
            " [   0    0    0    3    0    0    1    7    0    0  569]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "\n",
        "torch.save(model.state_dict(), 'mobilenetv2_fish_model.pth')"
      ],
      "metadata": {
        "id": "RLzLH_mChT2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bIZjdwQGiNuo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}