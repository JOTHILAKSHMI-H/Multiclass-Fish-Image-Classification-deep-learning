{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Multiclass Fish Image Classification using Pre-trained models**\n",
        "\n",
        "**VGG16**"
      ],
      "metadata": {
        "id": "D6Q-Vrgva3tY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqtLoyAlajvj"
      },
      "outputs": [],
      "source": [
        "#import the required libraries\n",
        "\n",
        "import os #manage path, folder, files\n",
        "\n",
        "import torch #building and training deeplearning model\n",
        "import torch.nn as nn # layer, activation & loss function\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzr5V5Ah5TNp",
        "outputId": "a385c2ff-ab53-418a-fb34-ea4743aa13f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set the device\n",
        "#this means you'll run your model on GPU\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device('cpu')\n"
      ],
      "metadata": {
        "id": "Eqyfjww_gVSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transformation for training data\n",
        "train_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomResizedCrop(224, scale = (0.8, 1.0)), #random zoom + crop\n",
        "        transforms.RandomHorizontalFlip(), #  flip the image (right ---> left)\n",
        "        transforms.RandomRotation(15), # random rotation clockwise or counter clockwise\n",
        "        transforms.ToTensor()   # #rescale to [0,1]\n",
        "    ])"
      ],
      "metadata": {
        "id": "3W6CHLVF7SRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #for test and val\n",
        "# data preprocessing\n",
        "\n",
        "test_val_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224, 224)), #resize piexel same as training\n",
        "        transforms.ToTensor() #convert image to tensor\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "IPFEXgc69Fyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the datasets\n",
        "train_datasets = datasets.ImageFolder('/content/drive/MyDrive/images.cv_jzk6llhf18tm3k0kyttxz/data/train', transform = train_transform)\n",
        "test_datasets = datasets.ImageFolder('/content/drive/MyDrive/images.cv_jzk6llhf18tm3k0kyttxz/data/test', transform = test_val_transform)\n",
        "val_datasets = datasets.ImageFolder('/content/drive/MyDrive/images.cv_jzk6llhf18tm3k0kyttxz/data/val', transform = test_val_transform)"
      ],
      "metadata": {
        "id": "aKsHtr0I9KmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-87InWG60UgK",
        "outputId": "bc3c286c-e659-4e8d-c85f-6f182e2da48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 6225\n",
              "    Root location: /content/drive/MyDrive/images.cv_jzk6llhf18tm3k0kyttxz/data/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the dataloader\n",
        "train_data_loader = DataLoader(train_datasets, batch_size = 5, shuffle = True)\n",
        "test_data_loader = DataLoader(test_datasets, batch_size = 5, shuffle = True)\n",
        "val_data_loader = DataLoader(val_datasets, batch_size = 5, shuffle = True)\n"
      ],
      "metadata": {
        "id": "eVSOdkIx96DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pre-trained  model VGG16\n",
        "model = models.vgg16(pretrained = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9V27GIF-CZR",
        "outputId": "fe87a56c-1390-4175-ef39-97c567b5a13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 153MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier[6] =nn.Linear(4096, 11)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "1ghfCA5C-brF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss function and optimizer\n",
        "\n",
        "cl = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(),lr = 0.001)"
      ],
      "metadata": {
        "id": "sB_rgL3zAA7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "\n",
        "epochs = 25\n",
        "\n",
        "for i in range(epochs):\n",
        "  model.train()\n",
        "  total_loss = 0.0 # total running loss\n",
        "  total = 0 #  #  Total number of images evaluated\n",
        "  correct = 0 #  calculate how many predictions correct\n",
        "\n",
        "  for img, tar in train_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(img)\n",
        "    loss = cl(outputs, tar)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    correct += (preds == tar).sum().item()\n",
        "    total += tar.size(0)\n",
        "\n",
        "  print(f\"Epoch [{i + 1}/{epochs}], loss {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "bWOXf5sWAFlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde89243-cc4d-4259-8241-e4df884fcce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], loss 3553.0251\n",
            "Epoch [2/25], loss 2978.3064\n",
            "Epoch [3/25], loss 2059.6943\n",
            "Epoch [4/25], loss 2369.0254\n",
            "Epoch [5/25], loss 2153.2963\n",
            "Epoch [6/25], loss 2199.5933\n",
            "Epoch [7/25], loss 2013.1498\n",
            "Epoch [8/25], loss 1840.0094\n",
            "Epoch [9/25], loss 1857.6461\n",
            "Epoch [10/25], loss 1791.8885\n",
            "Epoch [11/25], loss 1432.2816\n",
            "Epoch [12/25], loss 1876.3113\n",
            "Epoch [13/25], loss 1769.0886\n",
            "Epoch [14/25], loss 1659.1003\n",
            "Epoch [15/25], loss 1516.8948\n",
            "Epoch [16/25], loss 1196.7696\n",
            "Epoch [17/25], loss 1191.1553\n",
            "Epoch [18/25], loss 1801.6364\n",
            "Epoch [19/25], loss 1612.4228\n",
            "Epoch [20/25], loss 1331.4715\n",
            "Epoch [21/25], loss 1519.3809\n",
            "Epoch [22/25], loss 1091.9782\n",
            "Epoch [23/25], loss 1501.5024\n",
            "Epoch [24/25], loss 1192.9570\n",
            "Epoch [25/25], loss 934.9310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evlauate validation data"
      ],
      "metadata": {
        "id": "2iVS5QPf1I9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_tars = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for img, tar in val_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "    outputs = model(img)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_tars.extend(tar.cpu().numpy())\n",
        "\n",
        "\n",
        "  #accuracy\n",
        "  accuracy = accuracy_score(all_tars, all_preds)\n",
        "  print(f\"val_accuracy: {accuracy*100 :.2f}%\")\n",
        "\n",
        "  #precision\n",
        "  precision = precision_score(all_tars , all_preds, average = 'macro')\n",
        "  print(f\"val_precision: {precision*100 :.2f}%\")\n",
        "\n",
        "  # recall\n",
        "  recall = recall_score(all_tars , all_preds, average = 'macro')\n",
        "  print(f\"val_recall: {recall*100 :.2f}%\")\n",
        "\n",
        "\n",
        "#f1 score\n",
        "  f1score = f1_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"val f1_score: {f1score *100:.2f}%\")\n",
        "\n",
        "\n",
        "# Calculate confusion matrix\n",
        "  cm = confusion_matrix(all_tars, all_preds)\n",
        "  print('confusion matrix')\n",
        "  print(cm)"
      ],
      "metadata": {
        "id": "vWivmDpYyjAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f25fcb-b966-4fce-882c-70a88cb4b0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_accuracy: 98.44%\n",
            "val_precision: 89.66%\n",
            "val_recall: 90.33%\n",
            "val f1_score: 89.99%\n",
            "confusion matrix\n",
            "[[186   0   0   0   0   0   0   0   0   1   0]\n",
            " [  7   0   0   0   0   0   0   0   0   3   0]\n",
            " [  0   0 105   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0  94   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  97   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  90   0   0   0   0   0]\n",
            " [  0   0   0   2   0   0 111   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0  95   0   1   0]\n",
            " [  0   0   0   0   0   0   0   0 100   0   0]\n",
            " [  0   0   0   0   0   2   0   0   0  99   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  98]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on test data\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_tars = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for img, tar in test_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "    outputs = model(img)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_tars.extend(tar.cpu().numpy())\n",
        "\n",
        "\n",
        "# accuracy\n",
        "  accuracy = accuracy_score(all_tars, all_preds)\n",
        "  print(f\"Test Accuracy: {accuracy *100:.2f}%\")\n",
        "\n",
        "# precision\n",
        "  precision = precision_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"Test precision: {precision *100:.2f}%\")\n",
        "\n",
        "#recall\n",
        "  recall = recall_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"Test recall: {recall *100:.2f}%\")\n",
        "\n",
        "\n",
        "#f1 score\n",
        "  f1score = f1_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"Test f1_score: {f1score *100:.2f}%\")\n",
        "\n",
        "\n",
        "# Calculate confusion matrix\n",
        "  cm = confusion_matrix(all_tars, all_preds)\n",
        "  print('confusion matrix')\n",
        "  print(cm)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nl_WOEUE40nV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e2ebc0-6c94-435a-a70c-e30725264207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.59%\n",
            "Test precision: 89.81%\n",
            "Test recall: 89.95%\n",
            "Test f1_score: 89.86%\n",
            "confusion matrix\n",
            "[[520   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 13   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0 296   0   0   0   0   0   0   2   0]\n",
            " [  0   0   0 305   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 286   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 289   0   0   0   2   0]\n",
            " [  1   0   0   1   3   0 265   0   0   3   0]\n",
            " [  4   0   0   2   0   0   0 312   0   9   0]\n",
            " [  0   0   0   0   0   0   0   0 288   1   0]\n",
            " [  1   0   1   0   1   1   0   0   0 289   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 292]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the train data\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_tars = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  for img, tar in train_data_loader:\n",
        "    img, tar = img.to(device), tar.to(device)\n",
        "    outputs = model(img)\n",
        "    _,preds = torch.max(outputs, 1)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_tars.extend(tar.cpu().numpy())\n",
        "\n",
        "\n",
        "  # accuracy\n",
        "  accuracy = accuracy_score(all_tars, all_preds)\n",
        "  print(f\"Train Accuracy: {accuracy* 100:.2f}%\")\n",
        "\n",
        "  #precision\n",
        "  precision = precision_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"Train precision: {precision*100:.2f}%\")\n",
        "\n",
        "  #recall\n",
        "  recall = recall_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\"Train recall:{recall*100:.2f}%\")\n",
        "\n",
        "\n",
        "  #f1 score\n",
        "  f1score = f1_score(all_tars, all_preds, average = 'macro')\n",
        "  print(f\" f1_score: {f1score *100:.2f}%\")\n",
        "\n",
        "\n",
        "# Calculate confusion matrix\n",
        "  cm = confusion_matrix(all_tars, all_preds)\n",
        "  print('confusion matrix')\n",
        "  print(cm)"
      ],
      "metadata": {
        "id": "tU3b0QzU459v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6617df6-3890-47ba-be47-94ccc88f53f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 98.35%\n",
            "Train precision: 89.45%\n",
            "Train recall:89.74%\n",
            " f1_score: 89.58%\n",
            "confusion matrix\n",
            "[[1094    0    0    0    0    0    0    0    1    1    0]\n",
            " [  16    0    0    0    0    0    0    1    0   13    0]\n",
            " [   0    0  555    0    2    0    0    3    0    9    0]\n",
            " [   0    0    0  566    0    0    0    0    0    0    0]\n",
            " [   0    0    0    2  567    0    0    0    0    4    0]\n",
            " [   0    0    0    0    0  579    0    0    0    0    0]\n",
            " [   3    0    0    8    0    0  553    0    0    7    0]\n",
            " [   0    0    1    2    0    0    0  522    0   13    0]\n",
            " [   1    0    0    0    0    0    0    0  572    3    0]\n",
            " [   1    0    2    2    2    1    0    1    3  535    0]\n",
            " [   0    0    0    0    0    0    0    1    0    0  579]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "\n",
        "torch.save(model.state_dict(), 'vgg16_fish_model.pth')"
      ],
      "metadata": {
        "id": "lh3vjzS4nvdm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}